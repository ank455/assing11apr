{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c534a-96b3-49ea-80b5-22c16438fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 1\n",
    "An ensemble technique in machine learning is a method that combines multiple individual models to create a more powerful and robust predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24dcec-8a90-4d04-b76a-4c02cc4d19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans2 \n",
    "Ensemble techniques are widely used in machine learning for several reasons, as they offer several advantages and can address specific challenges encountered in building predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b4441-f478-4ba8-82e9-74c3caa84ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 3\n",
    "Bagging: In bagging, multiple instances of the same learning algorithm are trained on different subsets of the training data, each obtained by random sampling with replacement. The final prediction is usually the average or majority vote of the predictions made by the individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b6753-278f-487f-ba85-d507f2be8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans4\n",
    "Boosting: Boosting is an iterative ensemble technique where each new model is trained to correct the errors made by the previous model. The subsequent models give more weight to the misclassified instances of the previous models. Gradient Boosting Machines and AdaBoost are popular boosting algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b85fd0-d7f4-42a7-9bb7-3afb76d197a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 5\n",
    "Ensemble techniques offer several benefits in machine learning, making them a popular choice for improving model performance. \n",
    "\n",
    "(1) Improved Accuracy \n",
    "(2) Reduce Overfitting\n",
    "(3) Increase Robustness\n",
    "(4) Better Generalization\n",
    "(5) Flexibility\n",
    "(6) Easy Implementation\n",
    "(7) feature importance\n",
    "(8) Enabling Parallelization\n",
    "(9) Adaptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc374df-a712-4089-8a10-7d97b47467ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 6\n",
    "No, ensemble techniques are not always better than individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cafef9-5c38-46c3-9af9-0bf770917ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 7\n",
    "The confidence interval using bootstrap is calculated by repeatedly resampling the original dataset, constructing multiple bootstrap samples, and then calculating the statistic of interest for each resampled dataset. The confidence interval is then obtained from the distribution of these bootstrap statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0774afc-78b7-4d38-846b-040937118de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 8\n",
    "\n",
    "Bootstrap is a statistical resampling method used to estimate the uncertainty associated with a sample statistic without making strong assumptions about the underlying population distribution. It involves creating multiple random samples (bootstrap samples) with replacement from the original data and then using these samples to calculate the statistic of interest. By repeating this process numerous times, we can construct a distribution of the statistic, allowing us to estimate its variability and derive confidence intervals.\n",
    "\n",
    "The steps involved in bootstrap are as follows:\n",
    "\n",
    "1. Data Collection - Begin with a dataset containing observed data. This dataset may represent a sample from a larger population or a set of observations collected from a specific study or experiment.\n",
    "\n",
    "2. Resampling - Generate B bootstrap samples by randomly sampling N data points from the original dataset with replacement. Each bootstrap sample has the same size as the original dataset but may contain duplicate data points. Because sampling is done with replacement, some data points from the original dataset may appear multiple times in a bootstrap sample, while others may be left out.\n",
    "\n",
    "3. Statistic Calculation: For each of the B bootstrap samples, calculate the statistic of interest. This statistic could be the sample mean, median, variance, correlation, or any other parameter you want to estimate or compare.\n",
    "\n",
    "4.Bootstrap Distribution: After calculating the statistic for each bootstrap sample, you will have a collection of B bootstrap statistics, forming the bootstrap distribution. This distribution represents the variability of the statistic under repeated resampling from the original dataset.\n",
    "\n",
    "5.Confidence Interval Calculation: From the bootstrap distribution, you can calculate the confidence interval for the statistic. A common method is the percentile method, where you choose the lower and upper percentiles of the bootstrap distribution to form the interval. For example, a 95% confidence interval is usually obtained by taking the 2.5th and 97.5th percentiles of the bootstrap statistics.\n",
    "\n",
    "   Alternatively, you can use more advanced methods like the bias-corrected and accelerated (BCa) method, which adjusts the confidence interval to account for potential bias in the bootstrap distribution and provides more accurate intervals for small sample sizes or skewed data.\n",
    "\n",
    "6.Interpretation: The resulting confidence interval provides an estimate of the uncertainty associated with the statistic of interest. It helps to understand the range of values within which the true population parameter is likely to lie, given the observed data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c74174-fa29-47b7-a7cc-08dfe6f2a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 9\n",
    "\n",
    "##DataSet of 50 trees\n",
    "\n",
    "original_dataset=[15.5, 14.8, 15.2, 15.7, 14.9, 15.1, 15.3, 15.0, 15.4, 15.5,\n",
    " 15.1, 15.2, 14.9, 15.6, 15.2, 15.0, 15.3, 15.4, 15.1, 15.5,\n",
    " 14.8, 15.2, 15.7, 14.9, 15.1, 15.3, 15.0, 15.4, 15.5, 15.1,\n",
    " 15.2, 14.9, 15.6, 15.2, 15.0, 15.3, 15.4, 15.1, 15.5, 14.8,\n",
    " 15.2, 15.7, 14.9, 15.1, 15.3, 15.0, 15.4, 15.5, 15.1, 15.2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee3b49ca-c20b-4479-b746-12a64e3fc28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval for Population Mean Height:\n",
      "Lower bound: 15.16 meters\n",
      "Upper bound: 15.29 meters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "B = 1000\n",
    "\n",
    "bootstrap_sample_means = []\n",
    "\n",
    "for _ in range(B):\n",
    "    bootstrap_sample = np.random.choice(original_dataset, size=50, replace=True)\n",
    "    bootstrap_sample_mean = np.mean(bootstrap_sample)\n",
    "    bootstrap_sample_means.append(bootstrap_sample_mean)\n",
    "    \n",
    "    \n",
    "    \n",
    "confidence_interval = np.percentile(bootstrap_sample_means, [2.5, 97.5])\n",
    "\n",
    "print(\"95% Confidence Interval for Population Mean Height:\")\n",
    "print(f\"Lower bound: {confidence_interval[0]:.2f} meters\")\n",
    "print(f\"Upper bound: {confidence_interval[1]:.2f} meters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b603c-372c-46aa-89d2-653aa49d6037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
